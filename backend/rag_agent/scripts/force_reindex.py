#!/usr/bin/env python3
"""
Force Reindex Vector Store - Delete and recreate with better chunking
"""

import os
import sys
import shutil
from pathlib import Path

# Add the backend directory to the path
current_dir = Path(__file__).parent
rag_agent_dir = current_dir.parent
backend_dir = rag_agent_dir.parent
sys.path.insert(0, str(backend_dir))

def force_reindex():
    """Force reindex the vector store with better parameters."""
    print("\n" + "="*100)
    print("ğŸ”„ FORCE REINDEX VECTOR STORE")
    print("="*100)
    
    from rag_agent.utils.vector_store import VectorStoreManager
    from rag_agent.config.langchain import langchain_config
    import os
    
    # Configuration
    documents_path = "rag_agent/documents"
    vector_store_path = "rag_agent/data/vector_store"
    google_api_key = os.getenv("GOOGLE_API_KEY")
    
    print(f"\nğŸ“ Configuration:")
    print(f"   Documents path: {documents_path}")
    print(f"   Vector store path: {vector_store_path}")
    print(f"   Google API Key: {'âœ… Found' if google_api_key else 'âŒ Missing'}")
    
    # Delete existing vector store
    print(f"\nğŸ—‘ï¸  Deleting existing vector store...")
    vector_store_dir = Path(vector_store_path)
    if vector_store_dir.exists():
        shutil.rmtree(vector_store_dir)
        print("âœ… Existing vector store deleted")
    else:
        print("â„¹ï¸  No existing vector store found")
    
    # Create new vector store with BETTER chunking
    print(f"\nğŸ”„ Creating new vector store with optimized chunking...")
    
    # Use MUCH smaller chunks to ensure EQUIPMENT section is captured
    manager = VectorStoreManager(
        documents_path=documents_path,
        vector_store_path=vector_store_path,
        embedding_model=langchain_config.embedding_model,
        chunk_size=300,  # MUCH smaller chunks!
        chunk_overlap=50  # Less overlap for cleaner chunks!
    )
    
    # Initialize embeddings
    print(f"\nğŸ”„ Initializing embeddings...")
    success = manager.initialize_embeddings(google_api_key)
    if not success:
        print("âŒ Failed to initialize embeddings")
        return
    print("âœ… Embeddings initialized")
    
    # Load documents
    print(f"\nğŸ“„ Loading documents...")
    documents = manager.load_documents()
    if not documents:
        print("âŒ No documents found")
        return
    print(f"âœ… Loaded {len(documents)} documents")
    
    # Process into chunks
    print(f"\nğŸ”ª Processing documents into chunks...")
    chunks = manager.process_documents(documents)
    print(f"âœ… Created {len(chunks)} chunks")
    
    # Show chunk previews
    print(f"\nğŸ“‹ Chunk Preview:")
    for i, chunk in enumerate(chunks[:6]):  # Show first 6 chunks
        content_preview = chunk.page_content[:100].replace('\n', ' ')
        print(f"   Chunk {i+1}: {content_preview}...")
    
    # Create vector store
    print(f"\nğŸ”„ Creating FAISS vector store...")
    success = manager.create_vector_store(chunks)
    if not success:
        print("âŒ Failed to create vector store")
        return
    print("âœ… Vector store created successfully")
    
    # Save vector store to disk
    print(f"\nğŸ’¾ Saving vector store to disk...")
    success = manager.save_vector_store()
    if not success:
        print("âŒ Failed to save vector store")
        return
    print("âœ… Vector store saved successfully")
    
    # Test search
    print(f"\nğŸ§ª Testing search for EQUIPMENT...")
    results = manager.search_documents("equipment technology Zaman Bank", k=3)
    
    if results:
        print(f"âœ… Found {len(results)} results:")
        for i, result in enumerate(results, 1):
            score = result['similarity_score']
            content = result['content'][:150].replace('\n', ' ')
            print(f"   {i}. Score: {score:.4f} - {content}...")
    else:
        print("âŒ No results found for EQUIPMENT")
    
    print("\n" + "="*100)
    print("ğŸ‰ Force reindex complete!")
    print("="*100)

if __name__ == "__main__":
    force_reindex()
